name: invokeai

# Single docker-compose.yml for both local and TrueNAS Dockge
# Use environment variables to configure deployment-specific settings

# Any leasons we can learn from InvokeAI?
# https://github.com/invoke-ai/InvokeAI/blob/main/docker/docker-compose.yml
# @todo need to test this out and the swarm (rename all the swarm to stack? seems standard)
# @todo comfyui and invoke should share directory structure for outputs and models

services:
  invokeai:
    image: ghcr.io/invoke-ai/invokeai:latest
    container_name: invokeai
    environment:
      - INVOKEAI_ROOT=/workspace
      - INVOKEAI_HOST=0.0.0.0
      - INVOKEAI_PORT=9090
    volumes:
      - ${INVOKEAI_MODELS_PATH:-./models}:/workspace/models
      - ${INVOKEAI_OUTPUTS_PATH:-./outputs}:/workspace/outputs
      - ${INVOKEAI_CONFIGS_PATH:-./configs}:/workspace/configs
      - ${INVOKEAI_DATABASES_PATH:-./databases}:/workspace/databases
    networks:
      - proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.invoke.entrypoints=websecure"
      - "traefik.http.services.invoke.loadbalancer.server.port=9090"
      - "traefik.http.routers.invoke.service=invoke"
      - "traefik.http.routers.invoke.rule=Host(`invoke.${HOSTNAME:-pixeloven.com}`)"
      - "traefik.http.routers.invoke.tls=true"
      - "traefik.http.routers.invoke.tls.certresolver=letsencrypt"
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${GPU_DRIVER:-nvidia}
              count: ${GPU_COUNT:-all}
              capabilities: 
                - ${GPU_CAPABILITIES:-gpu}

networks:
  proxy:
    name: proxy
    external: true
