name: open-webui

services:
  # Open WebUI service
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    restart: unless-stopped
    networks:
      - proxy
      - open-webui
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      
      # Ollama Configuration
      - ENABLE_OLLAMA=${ENABLE_OLLAMA:-True}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_API_KEY=${OLLAMA_API_KEY:-ollama}
      
      # OpenAI Configuration
      - ENABLE_OPENAI_API=${ENABLE_OPENAI_API:-True}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-sk-proj-1234567890}
      
      # Web Search Configuration (RAG)
      - ENABLE_WEB_SEARCH=${ENABLE_WEB_SEARCH:-True}
      - WEB_SEARCH_ENGINE=${WEB_SEARCH_ENGINE:-searxng}
      - WEB_SEARCH_RESULT_COUNT=${WEB_SEARCH_RESULT_COUNT:-3}
      - WEB_SEARCH_CONCURRENT_REQUESTS=${WEB_SEARCH_CONCURRENT_REQUESTS:-10}
      - SEARXNG_QUERY_URL=http://searxng:8080/search?q=<query>
      
      # Whisper Speech-to-Text Configuration
      - ENABLE_WHISPER=${ENABLE_WHISPER:-True}
      - WHISPER_BASE_URL=${WHISPER_BASE_URL:-http://faster-whisper:10300}
      - WHISPER_MODEL=${WHISPER_MODEL:-tiny}
      - WHISPER_LANGUAGE=${WHISPER_LANGUAGE:-en}
      - WHISPER_TASK=${WHISPER_TASK:-transcribe}
      
      # Performance Optimization
      - BYPASS_WEB_SEARCH_EMBEDDING_AND_RETRIEVAL=${BYPASS_WEB_SEARCH_EMBEDDING_AND_RETRIEVAL:-False}
      - BYPASS_WEB_SEARCH_WEB_LOADER=${BYPASS_WEB_SEARCH_WEB_LOADER:-False}
      
      # Model Access Control
      - BYPASS_MODEL_ACCESS_CONTROL=${BYPASS_MODEL_ACCESS_CONTROL:-True} # so users can see the models set by the admin
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - open_webui_data:/app/backend/data
    extra_hosts:
      - host.docker.internal:host-gateway
    depends_on:
      ollama:
        condition: service_started
        required: true
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.open-webui.entrypoints=websecure"
      - "traefik.http.services.open-webui.loadbalancer.server.port=8080"
      - "traefik.http.routers.open-webui.service=open-webui"
      - "traefik.http.routers.open-webui.rule=Host(`open-webui.${DOMAIN_SUFFIX:-pixeloven.com}`)"
      - "traefik.http.routers.open-webui.tls=true"
      - "traefik.http.routers.open-webui.tls.certresolver=letsencrypt"

  # Ollama service with GPU acceleration
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    networks:
      - proxy
      - open-webui
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-24h}
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - ollama_data:/root/.ollama
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ollama.entrypoints=websecure"
      - "traefik.http.services.ollama.loadbalancer.server.port=11434"
      - "traefik.http.routers.ollama.service=ollama"
      - "traefik.http.routers.ollama.rule=Host(`ollama.${DOMAIN_SUFFIX:-pixeloven.com}`)"
      - "traefik.http.routers.ollama.tls=true"
      - "traefik.http.routers.ollama.tls.certresolver=letsencrypt"
      # - "traefik.http.routers.ollama.middlewares=ollama-auth"
      # - "traefik.http.middlewares.ollama-auth.basicauth.users=${OLLAMA_API_CREDENTIALS}"
    # GPU Configuration for Ollama:
    # - Set GPU_DRIVER, GPU_COUNT, GPU_CAPABILITIES in .env
    # - Supported drivers: nvidia, rocm, etc.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: ${GPU_DRIVER:-nvidia}
    #           count: ${GPU_COUNT:-all}
    #           capabilities: 
    #             - ${GPU_CAPABILITIES:-gpu}

  # Faster Whisper service with GPU acceleration
  faster-whisper:
    image: lscr.io/linuxserver/faster-whisper:latest
    container_name: faster-whisper
    restart: unless-stopped
    networks:
      - proxy
      - open-webui
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - TZ=${TZ:-Etc/UTC}
      - WHISPER_MODEL=${WHISPER_MODEL:-tiny}
      - WHISPER_LANG=${WHISPER_LANGUAGE:-en}
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - faster_whisper_data:/config
    # GPU Configuration for Faster Whisper:
    # - Set GPU_DRIVER, GPU_COUNT, GPU_CAPABILITIES in .env
    # - Supported drivers: nvidia, rocm, etc.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: ${GPU_DRIVER:-nvidia}
    #           count: ${GPU_COUNT:-all}
    #           capabilities: 
    #             - ${GPU_CAPABILITIES:-gpu}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.faster-whisper.entrypoints=websecure"
      - "traefik.http.services.faster-whisper.loadbalancer.server.port=10300"
      - "traefik.http.routers.faster-whisper.service=faster-whisper"
      - "traefik.http.routers.faster-whisper.rule=Host(`faster-whisper.${DOMAIN_SUFFIX:-pixeloven.com}`)"
      - "traefik.http.routers.faster-whisper.tls=true"
      - "traefik.http.routers.faster-whisper.tls.certresolver=letsencrypt"

networks:
  proxy:
    name: proxy
    external: true
  open-webui:
    name: open-webui

volumes:
  open_webui_data:
    name: open_webui_data
  ollama_data:
    name: ollama_data
  faster_whisper_data:
    name: faster_whisper_data
